---
layout: post
title:  "大模型问答"
date:   2026-02-01
last_modified_at: 2026-02-01
categories: [日常]
tags: [daily]
cover: https://qiniu.zhuyucun.cn/uploads/1764853276621_kn1jl7.jpg
---

## 摘要
面试中遇到的问题和回答，知识点问答

## chunk size 和 embedding 有什么关系？你是怎么选 chunk 的？  
Chunk size 和 embedding 本身没有直接关系，但会直接影响 embedding 能捕捉到的语义质量。Chunk 过小容易切断上下文，语义不完整；过大又可能混合多种语义，导致检索结果不够精准，同时也可能超过 embedding 模型的输入限制。

在实际项目中，我通常先根据文档结构确定一个初始范围，比如 300–800 token，并通过 overlap（如 10%–20%）来保证上下文连续性。然后用真实业务 query 进行测试，对比不同 chunk size 下的检索命中率和生成效果，最终选择在语义完整性和检索精度之间平衡的方案。  

对于结构清晰的文档（如合同、技术文档），chunk 可以偏大；而对叙述性或跨段落语义强的文档，会适当减小 chunk 并增加 overlap。