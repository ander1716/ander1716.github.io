---
layout: post
title: "RAG从零开始（一）"
date: 2025-12-15
last_modified_at: 2025-12-15
categories: [技术纵横]
tags: [rag]
cover: https://qiniu.zhuyucun.cn/uploads/1764853276621_kn1jl7.jpg
excerpt: >
  RAG是什么，RAG能做什么，RAG怎么用。
---

### 背景与问题
大模型虽学习过海量的数据，拥有几十亿到上万亿参数，但在特定领域或任务上的表现仍有限。这主要体现在以下几个方面：
- 知识时效性：每个模型的知识都在训练完成之日截止，而无法获取最新的信息。
- 知识覆盖度：大模型在训练时仅接触到公开的互联网数据，而无法获取私有的信息，比如公司内部资料。
- 幻觉问题：大模型在生成文本时，可能会生成看似合理但实际上是错误的内容。这主要是因为模型知识有限，在遇到知识盲区的时候就可能会“胡说八道”。

为了解决以上问题，有几种方案可选，一是提示词修改，二是微调大模型，三是RAG。  
- 提示词： 解决的问题有限，并且每次都要写繁杂的提示词，给用户增加了难度；    
- 微调模型： 成本高，需要大量的标注数据，并且模型的性能依赖于标注数据的质量。  
- Rag： 成本低，无需大量标注数据，只需要一个外部知识库。


### RAG是什么
RAG（Retrieval Augmented Generation），检索增强生成，旨在提升大语言模型（LLM）在特定任务中的准确性和效率，是一种结合了检索和生成两种方法的技术。   

简单理解：  
RAG = 大模型LLM + 外部数据（外挂知识库）  
将大模型不知道的知识通过增强提示词的方式，交给大模型来更好的回答用户的问题。

### 技术原理
1、检索与生成结合：RAG通过检索外部知识库（如企业文档、API定义等）获取相关上下文，再将这些信息输入大模型生成更精准的答案。

2、解决大模型局限性：通用大模型缺乏对私有或最新数据的访问能力，RAG通过动态检索补充知识，减少“幻觉”（即生成不准确内容）。

![rag](https://qiniu.zhuyucun.cn/uploads/1767338453472_3a2nwk.png)


**基本步骤：**  
1、索引化：文档分块—>文档向量化—>存储  
2、检索：用户提问—>问题向量化—>检索数据库—>得到top-k条相关文档  
3、生成：增强提示词（原始问题+相关文档块）—>给LLM—>生成答案  
注意：向量化必须使用同一个嵌入模型（向量模型）  

<!-- ### 参考 -->