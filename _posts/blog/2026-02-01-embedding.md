---
layout: post
title:  "embedding"
date:   2026-02-01
last_modified_at: 2026-02-01
categories: [日常]
tags: [daily]
cover: https://qiniu.zhuyucun.cn/uploads/1764853276621_kn1jl7.jpg
---

## 摘要
- embedding是什么  
- 特点  
- 为什么需要  
- 应用场景
- Embedding 怎么用？ 

## embedding是什么  
Embedding是将高维空间中的点映射到低维空间中的点的过程，他的作用是把 “非结构化数据”（文字、图片、音频、视频）变成 “计算机能理解的数字向量。  
Embedding是把现实世界中的东西，映射成一串固定长度的数字（向量）。  

## 特点  

- 降低纬度：纬度固定，通常是一个固定长度的向量，比如768 1024等，不同的模型有不同的Embedding长度  
- 结构化：将非结构化的数据映射到结构化的向量空间中  
- 保留语义：每个维度的数值都代表了不同的语义信息  
- 语义相似性：语义/内容越相似，向量之间的距离就越小  
- 可计算性：向量之间的距离可以用来计算相似度，比如余弦相似度  


## 为什么需要  
计算机只懂数字，而不懂文字、图片等语义信息，我们需要将这些非结构化的内容转为空间向量，再进行加减、比较和检索。  
这样，计算机就可以根据向量来进行计算、比较、检索和聚类等操作。  

## 应用场景
- 文本embedding：将文本映射为向量，用于文本分类、情感分析、信息检索等任务  

- 图片embedding：将图片映射为向量，用于图片分类、检索等任务  


## Embedding 怎么用？  
RAG（检索增强生成）：  
- 构建：   
1、将文本切成小块  
2、调用embedding模型 / 接口，将文本块映射为向量  
3、把向量、原文存储到向量数据库  
- 检索：  
1、用户输入问题  
2、对用户的输入进行向量化     
3、在向量数据库里搜索相似性最高的x条  
4、将这些向量对应的原文和用户提问交给大模型 
5、大模型根据原文和用户提问，生成回答  

## 总结  

Embedding 是将文本映射到高维语义空间中的向量表示，使语义相近的文本在向量空间中距离更近，从而支持语义检索。相似度检索本质是计算 query 向量与文档向量之间的相似度（通常使用 cosine similarity）。Token 是模型处理文本的最小单位，主要影响上下文长度和调用成本，与 embedding 维度不同。在 RAG 场景中，通常使用句级或段落级 embedding，通过合理的 chunk 策略在语义表达能力和检索效率之间取得平衡。
