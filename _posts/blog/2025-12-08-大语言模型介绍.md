---
layout: post
title: "什么是大模型"
date: 2025-12-08
last_modified_at: 2025-12-08
categories: [产品思维]
tags: [大模型]
cover: https://qiniu.zhuyucun.cn/uploads/1765206189153_i6ybt2.jpg
excerpt: >
  大语言模型介绍,是什么？能做什么？
---

### 什么是大语言模型？
俗称的大模型就是大语言模型，也就是我们说的LLM（Large Language Model），是基于深度学习训练而成的的模型，通过学习海量的文本数据，能够理解和生成自然语言。我们目前接触到的常用的就是最经典的GPT系列，DeepSeek还有豆包等等。

### 大语言模型的发展历史
- 早期阶段（1950s-1990s）：统计语言模型 
基于规则和语法分析、依赖概率计算等来实现的，人工智障的时代，通过传统的技术来支撑。

- 神经网络时代（2010s）：RNN/LSTM  
循环神经网络（RNN）是一种能够处理和建模序列数据的神经网络，

- Transformer革命（2017-2018）  
2017：Google发表《Attention Is All You Need》，提出Transformer架构，取代RNN，引入自注意力机制（Self-Attention），大幅提升模型并行计算能力。  
2018：
GPT-1（OpenAI）：首个基于Transformer的生成式预训练模型（1.17亿参数）。
BERT（Google）：采用双向Transformer，在多项NLP任务上刷新纪录（3.4亿参数）。

- 大模型爆发（2019-2022）：参数突破千亿  
2019：
GPT-2（OpenAI，15亿参数）展现强大文本生成能力，但因伦理问题暂未完全开源。
T5（Google）提出“Text-to-Text”统一框架，将所有NLP任务转化为文本生成。
2020：
GPT-3（OpenAI，1750亿参数）震撼发布，展示Few-shot Learning（少量示例即可完成任务）。
Turing-NLG（微软，170亿参数）、Megatron-Turing（微软 & NVIDIA，5300亿参数）加入竞争。

- 多模态与开源浪潮（2022-2024）  
2022：
ChatGPT（基于GPT-3.5）引爆全球AI热潮，展示强大对话能力。
BLOOM（BigScience，1760亿参数）和OPT（Meta，1750亿参数）推动开源大模型发展。
2023：
GPT-4（OpenAI，参数未公开）支持多模态（文本+图像），能力进一步提升。
LLaMA（Meta，7B-65B参数）开源，催生Alpaca、Vicuna等微调模型。
Claude（Anthropic）、Bard（Google）、文心一言（百度）等竞品涌现。
2024：
Gemini 1.5（Google）、Claude 3（Anthropic）、GPT-4 Turbo（OpenAI）持续升级。
开源模型爆发（如Mistral、DeepSeek、Qwen等），降低大模型使用门槛。


- 未来趋势  
更高效：模型压缩（如MoE架构）、低功耗推理（如Apple MLX）。
多模态：文本+图像+视频+音频的统一理解（如Sora、Gemini）。
AGI探索：从“工具”向“智能体”演进（如AutoGPT、AI Agent）。

- 总结  
大语言模型的发展经历了统计方法 → 神经网络 → Transformer → 千亿参数 → 多模态/开源的演进，未来将更注重实用性、安全性和低成本部署。



### 大语言模型是怎么工作的？
目前主流的大模型都是基于transformer架构的，transformer架构是一种基于自注意力机制的神经网络架构，能够处理序列数据，如文本。transformer架构的核心是自注意力机制，它能够在序列数据中学习到全局的依赖关系，从而更好地理解和生成文本。
用通俗的解释就是，transformer架构就像一个智能的翻译器，它能够理解输入文本中的每个单词之间的关系，然后根据这些关系生成输出文本。
比如用户输入一个今天，那根据大模型训练的海量文本，他会跟你补全后面的最可能出现的字、然后组成句、组成段落，也就是说按照概率学来补全的。

就像一个孩子，他天天都在接触新的事物，有一天有人问他“锄禾日当午”，他会毫不犹豫的说“汗滴禾下土”，这不是他创作的，而是他基于学习过的知识来回答的。

大模型学习的资料就是海量的文本数据，比如维基百科、新闻文章、书籍等等。这些数据都是大模型训练的基础，通过学习这些数据，大模型能够理解和生成自然语言。参数的意思就是模型中的可训练的变量，比如权重、偏置等等。参数的数量越多，模型的能力就越强，但是也会增加模型的计算量和存储需求。也就是学习的越多，模型的能力就越强，但是也会增加模型的训练时间和成本。


### 核心技术
#### 数据集预处理
- 分词
将文本转换为模型可识别的数值形式；
- 数据集预处理
移除低质量、重复、有害的数据； 
- 合成数据
当自然数据低或者是训练数据不足时使用另外一个LLM生成教科书式的训练。  

#### 训练过程
- 成本与规模
需要大量的基础设施训练成本与参数成正相关

- Fine-tuning
 预训练阶段：核心目标为预测下一个token
 微调阶段：通过人类反馈学习（RLHF）、指令微调等

### 大语言模型能做什么？
大语言模型能够做很多事情，比如：
- 文本生成：根据输入的文本提示，生成符合语法和逻辑的文本。
- 文本分类：将文本分类为预定义的类别，如情感分析、主题分类等。
- 问答系统：能够回答用户的问题，基于已有的知识和经验。
- 翻译：将一种语言的文本翻译成另一种语言。
- 代码生成：根据输入的代码提示，生成符合语法的代码。
- 文本摘要：将长文本压缩为短摘要，保留关键信息。
- 文本情感分析：分析文本中的情感倾向，如正面、负面或中性。


### 大语言模型的局限和风险？
**理解能力有限**： 他只能回答学习过的知识，也可以根据规则来回答，但是无法理解新的概念或事件。  
**文本生成依赖学习数据**：当训练的数据中存在偏见或错误时，大模型生成的文本也会存在偏见或错误。  
**计算资源成本高**：训练和使用大模型需要大量的计算资源，包括GPU和内存。  
**伦理问题**：大模型可能会生成有偏见或有害的文本，因此在使用时需要注意伦理问题。        
**不可控性**：同一个大模型，每次输出都可能不太一样，这取决于输入的文本提示和模型的训练数据。

### 总结  
大语言模型是一种基于transformer架构的神经网络模型，能够处理序列数据，它能够根据输入的文本提示生成符合语法和逻辑的文本。大语言模型的能力很强，但是也存在一些局限和风险，如理解能力有限、文本生成依赖学习数据、计算资源成本高、伦理问题和不可控性。因此，在使用大语言模型时需要注意这些问题，以确保模型的正确和安全使用。 


### 参考
- [Large language model](https://en.wikipedia.org/wiki/Large_language_model)
